# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OgEpm4Qp-TddmlynTRz-XUpWNFVsGPhD
"""

# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+
try:
    import torch
    import torchvision
    assert int(torch.__version__.split(".")[1]) >= 12 or int(torch.__version__.split(".")[0]) == 2, "torch version should be 1.12+"
    assert int(torchvision.__version__.split(".")[1]) >= 13, "torchvision version should be 0.13+"
    print(f"torch version: {torch.__version__}")
    print(f"torchvision version: {torchvision.__version__}")
except:
    print(f"[INFO] torch/torchvision versions not as required, installing nightly versions.")
    !pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    import torch
    import torchvision
    print(f"torch version: {torch.__version__}")
    print(f"torchvision version: {torchvision.__version__}")

# Continue with regular imports
import matplotlib.pyplot as plt
import torch
import torchvision

from torch import nn
from torchvision import transforms

# Try to get torchinfo, install it if it doesn't work
try:
    from torchinfo import summary
except:
    print("[INFO] Couldn't find torchinfo... installing it.")
    !pip install -q torchinfo
    from torchinfo import summary

# Try to import the going_modular directory, download it from GitHub if it doesn't work
try:
    from going_modular.going_modular import data_setup, engine
    from helper_functions import download_data, set_seeds, plot_loss_curves
except:
    # Get the going_modular scripts
    print("[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.")
    !git clone https://github.com/sgshiva25/FoodVision_Big.git
    !mv FoodVision_Big/going_modular .
    !mv FoodVision_Big/helper_functions.py . # get the helper_functions.py script
    !rm -rf FoodVision_Big
    from going_modular.going_modular import data_setup, engine
    from helper_functions import download_data, set_seeds, plot_loss_curves

device = "cuda" if torch.cuda.is_available() else "cpu"
device

"""#Creating a function to make an EffNetB2 feature extractor
The create_effnetb2_model() function is designed to create an EfficientNet-B2 feature extractor. It allows for customization of the number of output classes and accepts a random seed parameter to ensure reproducibility. The function returns both the EfficientNet-B2 model and its associated data transformation pipeline.
"""

def create_effnetb2_model(num_classes:int=3,
                          seed:int=42):
    """Creates an EfficientNetB2 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of classes in the classifier head.
            Defaults to 3.
        seed (int, optional): random seed value. Defaults to 42.

    Returns:
        model (torch.nn.Module): EffNetB2 feature extractor model.
        transforms (torchvision.transforms): EffNetB2 image transforms.
    """
    # 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model
    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.efficientnet_b2(weights=weights)

    # 4. Freeze all layers in base model
    for param in model.parameters():
        param.requires_grad = False

    # 5. Change classifier head with random seed for reproducibility
    torch.manual_seed(seed)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.3, inplace=True),
        nn.Linear(in_features=1408, out_features=num_classes),
    )

    return model, transforms

"""#  Creating a model and transforms for FoodVision Big

We can create an EffNetB2 feature extractor for Food101 by using our create_effnetb2_model() function we created above and passing it the parameter num_classes=101(since Food101 has 101 classes).
"""

# Create EffNetB2 model capable of fitting to 101 classes for Food101
effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101)

from torchinfo import summary

 # Get a summary of EffNetB2 feature extractor for Food101 with 101 output classes (uncomment for full output)
summary(effnetb2_food101,
        input_size=(1, 3, 224, 224),
        col_names=["input_size", "output_size", "num_params", "trainable"],
         col_width=20,
         row_settings=["var_names"])

"""The following code defines a data transformation pipeline that combines torchvision.transforms.TrivialAugmentWide()—a widely used data augmentation strategy employed in PyTorch vision —with preprocessing steps specifically tailored for EfficientNet-B2. This pipeline ensures that training images are augmented and normalized effectively to improve model performance."""

# Create Food101 training data transforms (only perform data augmentation on the training images)
food101_train_transforms = torchvision.transforms.Compose([
    torchvision.transforms.TrivialAugmentWide(),
    effnetb2_transforms,
])

# Comparing food101_train_transforms (for the training data) and effnetb2_transforms (for the testing/inference data).
print(f"Training transforms:\n{food101_train_transforms}\n")
print(f"Testing transforms:\n{effnetb2_transforms}")

"""# Getting data for FoodVision Big

For FoodVision Mini, we made our own custom data splits of the entire Food101 dataset.

To get the whole Food101 dataset, we can use torchvision.datasets.Food101().

We'll first setup a path to directory data/ to store the images.

Then we'll download and transform the training and testing dataset splits using food101_train_transforms and effnetb2_transforms to transform each dataset respectively.
"""

from torchvision import datasets

# Setup data directory
from pathlib import Path
data_dir = Path("data")

# Get training data (~750 images x 101 food classes)
train_data = datasets.Food101(root=data_dir, # path to download data to
                              split="train", # dataset split to get
                              transform=food101_train_transforms, # perform data augmentation on training data
                              download=True) # want to download?

# Get testing data (~250 images x 101 food classes)
test_data = datasets.Food101(root=data_dir,
                             split="test",
                             transform=effnetb2_transforms, # perform normal EffNetB2 transforms on test data
                             download=True)

"""The data has been successfully downloaded!

Next, the list of all class names can be accessed using train_data.classes.
"""

# Get Food101 class names
food101_class_names = train_data.classes

# View the first 10
food101_class_names[:10]

"""#Creating a Dataset Split Function
To create a 20% split for the FoodVision Big dataset, a function named split_dataset() will be implemented. This function will utilize torch.utils.data.random_split() to split a given dataset into specified proportions.

The lengths parameter of random_split() accepts a list of desired split sizes, where the total of the list must equal the overall dataset size.
For example, with a dataset of size 100, passing lengths=[20, 80] will yield a 20% and 80% split.

The function will return two splits:

One with the target length (e.g., 20% of the dataset).

The other with the remaining length (e.g., 80% of the dataset).

To ensure reproducibility, the function will also use the generator parameter with a torch.manual_seed() value.
"""

def split_dataset(dataset:torchvision.datasets, split_size:float=0.2, seed:int=42):
    """Randomly splits a given dataset into two proportions based on split_size and seed.

    Args:
        dataset (torchvision.datasets): A PyTorch Dataset, typically one from torchvision.datasets.
        split_size (float, optional): How much of the dataset should be split?
            E.g. split_size=0.2 means there will be a 20% split and an 80% split. Defaults to 0.2.
        seed (int, optional): Seed for random generator. Defaults to 42.

    Returns:
        tuple: (random_split_1, random_split_2) where random_split_1 is of size split_size*len(dataset) and
            random_split_2 is of size (1-split_size)*len(dataset).
    """
    # Create split lengths based on original dataset length
    length_1 = int(len(dataset) * split_size) # desired length
    length_2 = len(dataset) - length_1 # remaining length

    # Print out info
    print(f"[INFO] Splitting dataset of length {len(dataset)} into splits of size: {length_1} ({int(split_size*100)}%), {length_2} ({int((1-split_size)*100)}%)")

    # Create splits with given random seed
    random_split_1, random_split_2 = torch.utils.data.random_split(dataset,
                                                                   lengths=[length_1, length_2],
                                                                   generator=torch.manual_seed(seed)) # set the random seed for reproducible splits
    return random_split_1, random_split_2

# Create training 20% split of Food101
train_data_food101_20_percent, _ = split_dataset(dataset=train_data,
                                                 split_size=0.2)

# Create testing 20% split of Food101
test_data_food101_20_percent, _ = split_dataset(dataset=test_data,
                                                split_size=0.2)

len(train_data_food101_20_percent), len(test_data_food101_20_percent)

"""#Turning our Food101 datasets into DataLoaders

Next, the Food101 20% dataset splits will be converted into DataLoaders using torch.utils.data.DataLoader().

Key configurations for the DataLoaders include:

Setting shuffle=True for the training dataset only.

Using a batch size of 32 for both training and validation datasets.

Setting num_workers to 4 if the CPU count is available, otherwise defaulting to 2.

This setup ensures efficient data loading and optimal utilization of system resources.
"""

import os
import torch

BATCH_SIZE = 32
NUM_WORKERS = 2 if os.cpu_count() <= 4 else 4 # this value is very experimental and will depend on the hardware you have available, Google Colab generally provides 2x CPUs

# Create Food101 20 percent training DataLoader
train_dataloader_food101_20_percent = torch.utils.data.DataLoader(train_data_food101_20_percent,
                                                                  batch_size=BATCH_SIZE,
                                                                  shuffle=True,
                                                                  num_workers=NUM_WORKERS)
# Create Food101 20 percent testing DataLoader
test_dataloader_food101_20_percent = torch.utils.data.DataLoader(test_data_food101_20_percent,
                                                                 batch_size=BATCH_SIZE,
                                                                 shuffle=False,
                                                                 num_workers=NUM_WORKERS)

"""#Training FoodVision Big model

An optimizer will be created using torch.optim.Adam() with a learning rate of 1e-3.

Given the large number of classes, the loss function will be set up using torch.nn.CrossEntropyLoss() with label_smoothing=0.1, aligning with torchvision's state-of-the-art training practices.

What is Label Smoothing?
Label smoothing is a regularization technique designed to prevent overfitting by reducing a model's confidence in any single label. Instead of assigning a probability of 1 to the correct label and 0 to others, label smoothing spreads a small portion of the confidence across other labels.

This approach encourages the model to generalize better by preventing it from becoming overly confident in its predictions.

With label smoothing applied, the model remains confident in its prediction of class 3 but assigns small probabilities to other labels. This encourages the model to consider alternative options, improving its generalization ability.

To maintain efficiency, the model will be trained for five epochs using the engine.train() function. The primary objective is to surpass the original Food101 paper's test accuracy of 56.4%.
"""

from going_modular.going_modular import engine

# Setup optimizer
optimizer = torch.optim.Adam(params=effnetb2_food101.parameters(),
                             lr=1e-3)

# Setup loss function
loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1) # throw in a little label smoothing because so many classes

# Want to beat original Food101 paper with 20% of data, need 56.4%+ acc on test dataset
set_seeds()
effnetb2_food101_results = engine.train(model=effnetb2_food101,
                                        train_dataloader=train_dataloader_food101_20_percent,
                                        test_dataloader=test_dataloader_food101_20_percent,
                                        optimizer=optimizer,
                                        loss_fn=loss_fn,
                                        epochs=5,
                                        device=device)

"""The model successfully outperformed the original Food101 paper's accuracy of 56.4%, achieving this with only 20% of the training data. However, evaluation was conducted on 20% of the testing data as well; a complete replication of the original results would require evaluation on 100% of the testing data.

This achievement underscores the remarkable effectiveness of transfer learning.

#Inspecting loss curves of FoodVision Big model
The loss curves for FoodVision Big can be visualized using the plot_loss_curves() function from helper_functions.py. This provides a clear representation of the model's performance during training and evaluation.
"""

from helper_functions import plot_loss_curves

# Check out the loss curves for FoodVision Big
plot_loss_curves(effnetb2_food101_results)

"""#Saving and Loading FoodVisionBig"""

from going_modular.going_modular import utils

# Create a model path
effnetb2_food101_model_path = "09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"

# Save FoodVision Big model
utils.save_model(model=effnetb2_food101,
                 target_dir="models",
                 model_name=effnetb2_food101_model_path)

# Create Food101 compatible EffNetB2 instance
loaded_effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101)

# Load the saved model's state_dict()
loaded_effnetb2_food101.load_state_dict(torch.load("models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"))

"""FoodVision Big Model Size"""

from pathlib import Path

# Get the model size in bytes then convert to megabytes
pretrained_effnetb2_food101_model_size = Path("models", effnetb2_food101_model_path).stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly)
print(f"Pretrained EffNetB2 feature extractor Food101 model size: {pretrained_effnetb2_food101_model_size} MB")

